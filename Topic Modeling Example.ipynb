{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "In this workbook we loosely follow the example from \"Toward Data Science\" on\n",
    "[Topic Modeling with spaCy and gensim](https://towardsdatascience.com/building-a-topic-modeling-pipeline-with-spacy-and-gensim-c5dc03ffc619). First, we need to install gensim, so open up a command window (and I had to do it in \"administrator\"\n",
    "mode) and run this command: `pip install gensim`. We're also going to do some data viz, so run `pip install pyLDAvis`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel,LdaMulticore, Phrases \n",
    "from gensim.models.phrases import Phraser \n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "Lemmatizer = nlp.get_pipe(\"lemmatizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting to Know the Brown Corpus\n",
    "\n",
    "Let's spend a bit of time getting to know what's in the Brown corpus, our NLTK example of an \"overlapping\" corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories of articles in Brown corpus\n",
    "print(brown.categories())\n",
    "\n",
    "for category in brown.categories() :\n",
    "    print(f\"For {category} we have {len(brown.fileids(categories=category))} articles.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a list of the articles in of editorial, government, news, and romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_modeling = []\n",
    "\n",
    "for category in ['editorial','government','news','romance'] :\n",
    "    for file_id in brown.fileids(categories=category) :\n",
    "        text = brown.words(fileids=file_id)\n",
    "        for_modeling.append(\" \".join(text))\n",
    "        \n",
    "print(f\"We have {len(for_modeling)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates spaCy's default stop words list with my additional words. \n",
    "stop_list = ['`',\"Mr.\",\"Mrs.\",\"Ms.\"]\n",
    "nlp.Defaults.stop_words.update(stop_list)\n",
    "\n",
    "# Iterates over the words in the stop words list and resets the \"is_stop\" flag.\n",
    "for word in STOP_WORDS:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next two cells prepare our documents for the LDA algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "allowed_postags=['NOUN','ADJ','VERB','ADV']\n",
    "\n",
    "# Iterates through each article in the corpus.\n",
    "for doc in for_modeling :\n",
    "    # Passes that article through the pipeline and adds to a new list.\n",
    "    pr = nlp(doc)\n",
    "    doc_list.append([token.lemma_ for token in pr if token.pos_ in allowed_postags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id2word = Dictionary(doc_list)\n",
    "id2word.filter_extremes(no_below=10, no_above=0.4)\n",
    "id2word.compactify()\n",
    "corpus = [id2word.doc2bow(word) for word in doc_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we fit the actual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 7\n",
    "\n",
    "lda_model = LdaMulticore(corpus=corpus, \n",
    "                             id2word=id2word, \n",
    "                             num_topics=num_topics, \n",
    "                             random_state=1,\n",
    "                             chunksize=30,\n",
    "                             passes=20,\n",
    "                             alpha=0.31,\n",
    "                             eta=0.91,\n",
    "                             eval_every=1,\n",
    "                             per_word_topics=True,\n",
    "                             workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the model, both in terms of the words that define the model and via the visualization package `pyLDAvis`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyLDAvis.gensim.prepare(lda_model, corpus, words)\n",
    "pyLDAvis.gensim_models.prepare(lda_model, corpus,id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our topic classifications by document and see how good a job LDA is doing recovering our original topics. We'll take each document one at a time, parse it (as a joined string), and do basically the same processing as we did before. \n",
    "\n",
    "You can pass the processed document into the LDA model using square brackets (this is a bit odd) and recieve a tuple back. The first element of the tuple contains the topics and associated probabilities. The max probability will be the assigned topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_assignments = []\n",
    "\n",
    "for file_id in brown.fileids(categories=\"romance\") :\n",
    "    doc = brown.words(fileids=file_id)\n",
    "    pr = nlp(\" \".join(doc))\n",
    "    doc = [token.lemma_ for token in pr if token.pos_ in allowed_postags]\n",
    "    doc_new = id2word.doc2bow(doc)\n",
    "    \n",
    "    topic_probs = lda_model[doc_new][0]\n",
    "    topic = max(topic_probs,key=lambda x: x[1])\n",
    "    topic_assignments.append(topic[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at those topic assignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(topic_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like topic five is overwhelmingly romance. Let's do this for every category we worked with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_assignments = defaultdict(list)\n",
    "\n",
    "for category in ['editorial','government','news','romance'] :\n",
    "    for file_id in brown.fileids(categories=category) :\n",
    "\n",
    "        doc = brown.words(fileids=file_id)\n",
    "        pr = nlp(\" \".join(doc))\n",
    "        doc = [token.lemma_ for token in pr if token.pos_ in allowed_postags]\n",
    "        doc_new = id2word.doc2bow(doc)\n",
    "\n",
    "        topic_probs = lda_model[doc_new][0]\n",
    "        topic = max(topic_probs,key=lambda x: x[1])\n",
    "        topic_assignments[category].append(topic[0])\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat, topic_list in topic_assignments.items() :\n",
    "    print(f\"In {cat} we had the following:\")\n",
    "    topic_count = Counter(topic_list).most_common()\n",
    "    \n",
    "    for topic, count in topic_count : \n",
    "        print(f\"    {count} articles were classified as topic {topic}.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this assignment is pretty imperfect, though the categories overlap pretty heavily, particularly the first three. Romance seems to be safely identified on its own. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
